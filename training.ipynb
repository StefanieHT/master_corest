{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f6e091-a326-4d88-835d-d1134d170f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up plotting options\n",
    "!pip install torchmetrics\n",
    "%matplotlib inline\n",
    "!pip install -U git+https://github.com/albu/albumentations --no-cache-di\n",
    "!pip install segmentation-models-pytorch\n",
    "!pip install psutil\n",
    "!pip install --extra-index-url=https://pypi.nvidia.com cudf-cu12==24.8.* dask-cudf-cu12==24.8.* cuml-cu12==24.8.* cugraph-cu12==24.8.* cuspatial-cu12==24.8.* cuproj-cu12==24.8.* cuxfilter-cu12==24.8.* cucim-cu12==24.8.* pylibraft-cu12==24.8.* raft-dask-cu12==24.8.* cuvs-cu12==24.8.*\n",
    "#!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
    "#!python rapidsai-csp-utils/colab/pip-install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f80ce21-30cb-421c-a125-f3378bc7fe39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import psutil\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, RandomSampler, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torchmetrics import ConfusionMatrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import albumentations as A\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae679e6a-ee8e-45ec-a68a-114095607a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class iouTracker:\n",
    "    def __init__(self, n_classes=2, smooth=1e-6):\n",
    "        self.n_classes = n_classes\n",
    "        self.smooth = smooth\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cm = np.zeros((self.n_classes, self.n_classes), dtype=np.float64)\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        # pred: [B, 2, H, W]\n",
    "        # target: [B, H, W]\n",
    "\n",
    "        # reshape and move to CPU\n",
    "        pred = pred.argmax(dim=1).flatten().detach().cpu().numpy()\n",
    "        target = target.flatten().detach().cpu().numpy()\n",
    "\n",
    "        # ensure 2x2 confusion matrix\n",
    "        self.cm += confusion_matrix(target, pred, labels=[0, 1])\n",
    "\n",
    "    def get_mean(self):\n",
    "        # Extract TP, FP, FN for class 1 (Flood)\n",
    "        TP = self.cm[1, 1]\n",
    "        FP = self.cm[0, 1]\n",
    "        FN = self.cm[1, 0]\n",
    "\n",
    "        # Compute IoU for class 1\n",
    "        iou = TP / (TP + FP + FN + self.smooth)\n",
    "        return iou\n",
    "\n",
    "\n",
    "class ETCIDataset(Dataset):\n",
    "    def __init__(self, dataframe, split, transform=None):\n",
    "        self.split = split\n",
    "        self.dataset = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset.shape[0]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = {}\n",
    "\n",
    "        df_row = self.dataset.iloc[index]\n",
    "\n",
    "        # load vv and vh images\n",
    "        vv_image = cv2.imread(df_row['vv_image_path'], 0) / 255.0\n",
    "        vh_image = cv2.imread(df_row['vh_image_path'], 0) / 255.0\n",
    "\n",
    "        # convert vv and ch images to rgb\n",
    "        rgb_image = s1_to_rgb(vv_image, vh_image)\n",
    "\n",
    "        if self.split == 'test':\n",
    "            # no flood mask should be available\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "        else:\n",
    "            # load ground truth flood mask\n",
    "            flood_mask = cv2.imread(df_row['flood_label_path'], 0) / 255.0\n",
    "\n",
    "            # compute transformations\n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=rgb_image, mask=flood_mask)\n",
    "                rgb_image = augmented['image']\n",
    "                flood_mask = augmented['mask']\n",
    "\n",
    "            example['image'] = rgb_image.transpose((2,0,1)).astype('float32')\n",
    "            example['mask'] = flood_mask.astype('int64')\n",
    "\n",
    "        return example\n",
    "\n",
    "    \n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomResizedCrop(size=[256, 256])\n",
    "])\n",
    "\n",
    "\n",
    "def get_filename(filepath):\n",
    "    return os.path.split(filepath)[1]\n",
    "\n",
    "\n",
    "\n",
    "def s1_to_rgb(vv_image, vh_image):\n",
    "    ratio_image = np.clip(np.nan_to_num(vh_image/vv_image, 0), 0, 1)\n",
    "    rgb_image = np.stack((vv_image, vh_image, 1-ratio_image), axis=2)\n",
    "    return rgb_image\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "  # load model from package\n",
    "  model = smp.Unet(\n",
    "      encoder_name=\"resnet34\",        \n",
    "      encoder_weights=None,           \n",
    "      in_channels=3,                  \n",
    "      classes=2,                      \n",
    "  )\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def log_system_usage(task, gpu_memory_allocated, gpu_memory_reserved, cpu_percent, memory_percent, elapsed_time):\n",
    "    log_message = (f\"Task: {task}, GPU Memory Allocated: {gpu_memory_allocated:.2f} MB, \"\n",
    "                   f\"GPU Memory Reserved: {gpu_memory_reserved:.2f} MB, CPU Usage: {cpu_percent:.2f}%, \"\n",
    "                   f\"Memory Usage: {memory_percent:.2f}%, Elapsed Time: {elapsed_time:.2f} seconds\")\n",
    "    logger.info(log_message)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a5a3f-42aa-4bd2-839d-c03830080e9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up the logger\n",
    "logger = logging.getLogger('TrainingLogger')\n",
    "logger.setLevel(logging.INFO)\n",
    "fh = logging.FileHandler('training_logs.txt')\n",
    "fh.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f044826-9cbf-4367-9687-49a40cfab408",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def prepare_dataset_paths(dset_root):\n",
    "    train_dir = os.path.join(dset_root, 'train')\n",
    "    n_train_regions = len(glob(train_dir + '/*/'))\n",
    "    print('Number of training temporal-regions: {}'.format(n_train_regions))\n",
    "\n",
    "    vv_image_paths = sorted(glob(train_dir + '/**/vv/*.png', recursive=True))\n",
    "    vv_image_names = [get_filename(pth) for pth in vv_image_paths]\n",
    "    region_name_dates = ['_'.join(n.split('_')[:2]) for n in vv_image_names]\n",
    "\n",
    "    vh_image_paths, flood_label_paths, region_names = [], [], []\n",
    "    for i in range(len(vv_image_paths)):\n",
    "        vh_image_name = vv_image_names[i].replace('vv', 'vh')\n",
    "        vh_image_path = os.path.join(train_dir, region_name_dates[i], 'tiles', 'vh', vh_image_name)\n",
    "        vh_image_paths.append(vh_image_path)\n",
    "\n",
    "        flood_image_name = vv_image_names[i].replace('_vv', '')\n",
    "        flood_label_path = os.path.join(train_dir, region_name_dates[i], 'tiles', 'flood_label', flood_image_name)\n",
    "        flood_label_paths.append(flood_label_path)\n",
    "\n",
    "        region_name = region_name_dates[i].split('_')[0]\n",
    "        region_names.append(region_name)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        'vv_image_path': vv_image_paths,\n",
    "        'vh_image_path': vh_image_paths,\n",
    "        'flood_label_path': flood_label_paths,\n",
    "        'region': region_names\n",
    "    })\n",
    "\n",
    "\n",
    "def split_dataset(train_df, seed=4):\n",
    "    sub_train_df, development_df = train_test_split(train_df, test_size=0.2, random_state=seed)\n",
    "    sub_train_df = sub_train_df.reset_index(drop=False)\n",
    "    development_df = development_df.reset_index(drop=False)\n",
    "\n",
    "    development_df, test_df = train_test_split(development_df, test_size=0.5, random_state=seed)\n",
    "    development_df = development_df.reset_index(drop=False)\n",
    "    test_df = test_df.reset_index(drop=False)\n",
    "\n",
    "    print(f\"Training set size: {sub_train_df.shape[0]}\")\n",
    "    print(f\"Development set size: {development_df.shape[0]}\")\n",
    "    print(f\"Test set size: {test_df.shape[0]}\")\n",
    "\n",
    "    return sub_train_df, development_df, test_df\n",
    "\n",
    "\n",
    "def get_dataloaders(sub_train_df, development_df, batch_size, transform=None, coreset_indices=None):\n",
    "    if coreset_indices is not None:\n",
    "        train_df = sub_train_df[sub_train_df['index'].isin(core_set_indices)]\n",
    "        print(f\"Using core set of size {len(train_df)}\")\n",
    "    else:\n",
    "        train_df = sub_train_df\n",
    "        print(f\"Using full training set of size {len(train_df)}\")\n",
    "\n",
    "    train_dataset = ETCIDataset(train_df, split='train', transform=transform)\n",
    "    sampler = RandomSampler(train_dataset, generator=torch.Generator().manual_seed(4))\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        sampler=sampler,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    development_dataset = ETCIDataset(development_df, split='devlopment', transform=None)\n",
    "    development_loader = DataLoader(\n",
    "        development_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=2,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    return train_loader, development_loader\n",
    "\n",
    "\n",
    "\n",
    "def initialize_training(model, learning_rate):\n",
    "    model = model.to('cuda')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    return model, optimizer, scheduler, loss_fn\n",
    "\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    return generator\n",
    "\n",
    "\n",
    "def load_coreset(path):\n",
    "    with open(path, 'r') as json_file:\n",
    "        core_set_indices = json.load(json_file)\n",
    "    print(f\"coreset size: {len(core_set_indices)}\")\n",
    "    return core_set_indices\n",
    "\n",
    "\n",
    "def validate_model(model, dataloader, loss_fn, device='cuda'):\n",
    "    model.eval()\n",
    "    iou_logger = iouTracker()\n",
    "    total_loss = 0\n",
    "\n",
    "    pbar = tqdm(dataloader)\n",
    "    with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            loss = loss_fn(pred, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            iou_logger.update(pred, mask)\n",
    "            mIoU = iou_logger.get_mean()\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f} | mIoU {mIoU:.4f}\")\n",
    "\n",
    "    mean_iou = iou_logger.get_mean()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    return avg_loss, mean_iou\n",
    "\n",
    "def train_model(model, train_loader, development_loader, optimizer, scheduler, criteria, samples, epochs=100, patience=10, device='cuda'):\n",
    "    loss_list = []\n",
    "    iou_list = []\n",
    "    results_log = {\"train_loss\": [], \"train_iou\": [], \"dev_loss\": [], \"dev_iou\": []}\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        logger.info(f\"samples: {samples}\")\n",
    "        logger.info('Epoch: [{}/{}]'.format(epoch, epochs))\n",
    "\n",
    "        # TRAIN \n",
    "        model.train()\n",
    "        iou_logger = iouTracker()\n",
    "        total_loss = 0\n",
    "        pbar = tqdm(train_loader)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        logger.info(f\"Current Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        for batch in pbar:\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            loss = criteria(pred, mask)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iou_logger.update(pred, mask)\n",
    "            mIoU = iou_logger.get_mean()\n",
    "            pbar.set_description(f\"Loss: {loss.item():.4f} | mIoU {mIoU:.4f}\")\n",
    "\n",
    "        mean_iou = iou_logger.get_mean()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        results_log[\"train_loss\"].append(round(avg_loss, 4))\n",
    "        results_log[\"train_iou\"].append(round(mean_iou, 4))\n",
    "        logger.info(f\"Training Set Evaluation - Loss: {avg_loss:.4f}, mIoU: {mean_iou:.4f}\")\n",
    "\n",
    "        # VALIDATION \n",
    "        val_loss, val_iou = validate_model(model, development_loader, criteria, device)\n",
    "        results_log[\"dev_loss\"].append(round(val_loss, 4))\n",
    "        results_log[\"dev_iou\"].append(round(val_iou, 4))\n",
    "        logger.info(f\"Development Set Evaluation - Loss: {val_loss:.4f}, mIoU: {val_iou:.4f}\")\n",
    "\n",
    "        # --- EARLY STOPPING ---\n",
    "        if avg_loss < best_val_loss:\n",
    "            best_val_loss = avg_loss\n",
    "            epochs_no_improve = 0\n",
    "            logger.info(\"Validation loss improved, saving the model.\")\n",
    "            torch.save(model.state_dict(), f'models/{samples}_epoch{epoch}.pt')\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            logger.info(f\"No improvement in validation loss for {epochs_no_improve} epochs.\")\n",
    "            if epochs_no_improve == patience:\n",
    "                logger.info(f\"Early stopping triggered. No improvement for {patience} epochs.\")\n",
    "                break\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "        torch.save(model.state_dict(), f'models/{samples}_current.pt')\n",
    "\n",
    "    with open(f'results/{samples}_training_results.json', 'w') as outfile:\n",
    "        json.dump(results_log, outfile)\n",
    "\n",
    "    final_model_name = f'models/{samples}_epoch{epoch}.pt'\n",
    "    torch.save(model.state_dict(), final_model_name)\n",
    "    logger.info(\"Model trained on full set saved as \" + final_model_name)\n",
    "\n",
    "    return results_log\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f0c34-a448-4c41-834b-e55616d84988",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run training\n",
    "dset_root = 'dataset/ETCI_2021_Competition_Dataset/'\n",
    "train_df = prepare_dataset_paths(dset_root)\n",
    "sub_train_df, development_df, test_df = split_dataset(train_df)\n",
    "\n",
    "\n",
    "coreset_indices = load_coreset('experiments/kmeans_encoder_sampling/samples_kmeans_03_encoder_01.json')\n",
    "\n",
    "train_loader, development_loader = get_dataloaders(\n",
    "    sub_train_df,\n",
    "    development_df,\n",
    "    batch_size=64,\n",
    "    transform=transform,\n",
    "    coreset_indices=coreset_indices  \n",
    ")\n",
    "\n",
    "set_seed(42)\n",
    "model = create_model()\n",
    "model, optimizer, scheduler, criteria = initialize_training(model, learning_rate=1e-3)\n",
    "\n",
    "results_log = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    development_loader=development_loader,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criteria=criteria,\n",
    "    samples='samples_kmeans_03_encoder_01',\n",
    "    epochs=100,\n",
    "    patience=10,\n",
    "    device='cuda'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde5afc-aa92-4260-9f96-4c2ea614e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run testing\n",
    "\n",
    "def evaluate_model(model, dataloader, device='cuda', num_classes=2):\n",
    "    model.eval()\n",
    "    confmat = ConfusionMatrix(task=\"multiclass\", num_classes=num_classes).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            image = batch['image'].to(device)\n",
    "            mask = batch['mask'].to(device)\n",
    "\n",
    "            pred = model(image)\n",
    "            pred_labels = torch.argmax(pred, dim=1)\n",
    "            confmat.update(pred_labels, mask)\n",
    "\n",
    "    cm = confmat.compute().cpu().numpy()\n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, filename):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "    print(f\"Confusion matrix saved as {filename}\")\n",
    "\n",
    "def compute_metrics(cm):\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    TP = cm[1, 1]\n",
    "\n",
    "    iou_bg = TN / (TN + FN + FP + 1e-6)\n",
    "    iou_flood = TP / (TP + FP + FN + 1e-6)\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "\n",
    "    return {\n",
    "        \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP,\n",
    "        \"IoU_bg\": iou_bg, \"IoU_flood\": iou_flood,\n",
    "        \"Precision\": precision, \"Recall\": recall, \"F1\": f1\n",
    "    }\n",
    "\n",
    "\n",
    "test_dataset = ETCIDataset(test_df, split='devlopment', transform=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = UNetWithEmbeddings(encoder_name=\"resnet34\", encoder_weights=None, in_channels=3, classes=2)\n",
    "model.load_state_dict(torch.load('models/samples_kmeans_03_encoder_01_epoch68.pt', map_location=device))\n",
    "model.to(device)\n",
    "\n",
    "cm = evaluate_model(model, test_loader, device=device)\n",
    "metrics = compute_metrics(cm)\n",
    "\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")\n",
    "\n",
    "plot_confusion_matrix(cm, [\"Background\", \"Flood\"], \"confusion_matrix_samples_kmeans_03_encoder_01.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
